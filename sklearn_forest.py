
#!/usr/bin/python3
import os
import joblib
import sklearn
import sklearn.ensemble
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix, classification_report


data = pd.read_csv("/data_final.csv")
features = data.iloc[:,:-1].values
labels = data.iloc[:,-1].values
model_output_path = " "
"""
train_forest_classifer will train a RandomForestClassifier

features: 2D array of each input feature for each sample
labels: array of string labels classifying each sample
model_output_path: path for storing the trained forest model
"""
# save 20% of data for performance evaluation
X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)

param = [
    {
        "max_depth": [None, 10, 100, 1000, 10000],
        "n_estimators": [1, 10, 100]
    }
]

forest = RandomForestClassifier(random_state=0)

# 10-fold cross validation, use 4 thread as each fold and each parameter set can be train in parallel
clf = GridSearchCV(forest, param,
        cv=10, n_jobs=20, verbose=3)

clf.fit(X_train, y_train)

if os.path.exists(model_output_path):
    joblib.dump(clf.best_estimator_, model_output_path)
else:
    print("Cannot save trained forest model to {0}.".format(model_output_path))

print("\nBest parameters set:")
print(clf.best_params_)

y_predict=clf.predict(X_test)

labels=sorted(list(set(labels)))
print("\nConfusion matrix:")
labels = [str(i) for i in labels]
print("Labels: {0}\n".format(",".join(labels)))
print(confusion_matrix(y_test, y_predict, labels=labels))

print("\nClassification report:")
print(classification_report(y_test, y_predict))



